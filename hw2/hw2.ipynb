{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "ntdUgYO9PK7y"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from numpy.linalg import norm\n",
    "import heapq\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "x_slice = 5\n",
    "y_slice = 5\n",
    "\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, dataset_folder):\n",
    "        self.dataset_folder = dataset_folder\n",
    "\n",
    "    def prepare_reference(self, dataset, folder='Reference'):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def extract_from_dataset(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "# * [Grid Color Moments](http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/AV0405/KEEN/av_as2_nkeen.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "ntdUgYO9PK7y"
   },
   "outputs": [],
   "source": [
    "class GridColorMomentsExtractor(FeatureExtractor):\n",
    "    def __init__(self, dataset_folder):\n",
    "        super().__init__(dataset_folder)\n",
    "        if not os.path.isfile(f'{dataset_folder}-Reference.npy'):\n",
    "            self.prepare_reference(dataset_folder)\n",
    "        self.reference = np.load(f'{dataset_folder}-Reference.npy')\n",
    "\n",
    "    def prepare_reference(self, dataset, folder='Reference'):\n",
    "        train_data_path = os.path.join(dataset, folder)\n",
    "        images = sorted([item for item in os.listdir(\n",
    "            train_data_path) if item.endswith('.jpg')])\n",
    "        total = len(images)\n",
    "\n",
    "        print('-'*30)\n",
    "        print('Preparing reference...')\n",
    "        print('-'*30)\n",
    "\n",
    "        image_moments = np.ndarray((total, x_slice, y_slice, 3, 3), np.float32)\n",
    "\n",
    "        for idx, image_name in enumerate(images):\n",
    "            img = cv2.imread(os.path.join(train_data_path, image_name))\n",
    "            dx = img.shape[0] // x_slice\n",
    "            dy = img.shape[1] // y_slice\n",
    "\n",
    "            for i in range(x_slice):\n",
    "                for j in range(y_slice):\n",
    "                    img_slice = img[i*dx:(i+1)*dx, j*dy:(j+1)*dy]\n",
    "                    slice_moment = GridColorMomentsExtractor.color_moments(\n",
    "                        img_slice)\n",
    "                    image_moments[idx][i][j] = slice_moment\n",
    "\n",
    "            if idx % 10 == 0:\n",
    "                print(f'Done: {idx}/{total} images')\n",
    "\n",
    "        print('Loading done.')\n",
    "\n",
    "        np.save(f'{dataset}-{folder}.npy', image_moments)\n",
    "        print(f'Saving to {dataset}-{folder}.npy files done.')\n",
    "\n",
    "    def extract_from_dataset(self):\n",
    "        subfolders = [item for item in os.listdir(self.dataset_folder) if item not in [\n",
    "            \".DS_Store\", \"Reference\"]]\n",
    "        top1_sum = 0\n",
    "        top5_sum = 0\n",
    "        total_count = 0\n",
    "        for subfolder in subfolders:\n",
    "            top1_count, top5_count = self._extract_from_subfolder(subfolder)\n",
    "            top1_sum += top1_count\n",
    "            top5_sum += top5_count\n",
    "            total_count += len(self.reference)\n",
    "\n",
    "        return top1_sum, top5_sum, total_count\n",
    "\n",
    "    def _extract_from_subfolder(self, subfolder):\n",
    "        train_data_path = os.path.join(self.dataset_folder, subfolder)\n",
    "        images = sorted([item for item in os.listdir(\n",
    "            train_data_path) if item.endswith('.jpg')])\n",
    "\n",
    "        total = len(images)\n",
    "\n",
    "        print('-'*30)\n",
    "        print(f'Classifying {subfolder}...')\n",
    "        print('-'*30)\n",
    "\n",
    "        top1_count = 0\n",
    "        top5_count = 0\n",
    "\n",
    "        weight = np.reshape(np.array(x_slice * y_slice * [\n",
    "            [1, 0, 0],\n",
    "            [0, 2, 0],\n",
    "            [0, 0, 1]\n",
    "        ]), (x_slice, y_slice, 3, 3))\n",
    "\n",
    "        for idx, image_name in enumerate(images):\n",
    "            img = cv2.imread(os.path.join(train_data_path, image_name))\n",
    "            dx = img.shape[0] // x_slice\n",
    "            dy = img.shape[1] // y_slice\n",
    "\n",
    "            image_moment = np.ndarray((x_slice, y_slice, 3, 3), np.float32)\n",
    "\n",
    "            for i in range(x_slice):\n",
    "                for j in range(y_slice):\n",
    "                    img_slice = img[i*dx:(i+1)*dx, j*dy:(j+1)*dy]\n",
    "                    slice_moment = GridColorMomentsExtractor.color_moments(\n",
    "                        img_slice)\n",
    "                    image_moment[i][j] = slice_moment\n",
    "\n",
    "            possible_values = []\n",
    "            for reference_index in range(self.reference.shape[0]):\n",
    "                substracted_mat = np.subtract(\n",
    "                    self.reference[reference_index], image_moment)\n",
    "                mat = np.matmul(substracted_mat, weight)\n",
    "                distance = norm(mat)\n",
    "                heapq.heappush(possible_values, (distance, reference_index))\n",
    "\n",
    "            top5_values = []\n",
    "            for i in range(5):\n",
    "                top5_values.append(heapq.heappop(possible_values))\n",
    "            top5 = [index for distance, index in top5_values]\n",
    "\n",
    "            if idx in top5_values[0]:\n",
    "                top1_count += 1\n",
    "                print(f'hit: {image_name}! Distance:{top5_values[0][0]}')\n",
    "\n",
    "            if idx in top5:\n",
    "                top5_count += 1\n",
    "                distance, index = [\n",
    "                    entry for entry in top5_values if entry[1] == idx][0]\n",
    "                print(f'hit in top 5: {image_name}! Distance:{distance}')\n",
    "\n",
    "            if idx % 10 == 0:\n",
    "                print(f'Done: {idx}/{total} images')\n",
    "\n",
    "        print('All done.')\n",
    "        return top1_count, top5_count\n",
    "\n",
    "    @staticmethod\n",
    "    def color_moments(img):\n",
    "        if img is None:\n",
    "            return\n",
    "        # Convert BGR to HSV colorspace\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        # Split the channels - h,s,v\n",
    "        h, s, v = cv2.split(hsv)\n",
    "        # Initialize the color feature\n",
    "        color_feature = []\n",
    "        # N = h.shape[0] * h.shape[1]\n",
    "        # The first central moment - average\n",
    "        h_mean = np.mean(h)  # np.sum(h)/float(N)\n",
    "        s_mean = np.mean(s)  # np.sum(s)/float(N)\n",
    "        v_mean = np.mean(v)  # np.sum(v)/float(N)\n",
    "        color_feature.append([h_mean, s_mean, v_mean])\n",
    "        # The second central moment - standard deviation\n",
    "        h_std = np.std(h)  # np.sqrt(np.mean(abs(h - h.mean())**2))\n",
    "        s_std = np.std(s)  # np.sqrt(np.mean(abs(s - s.mean())**2))\n",
    "        v_std = np.std(v)  # np.sqrt(np.mean(abs(v - v.mean())**2))\n",
    "        color_feature.append([h_std, s_std, v_std])\n",
    "        # The third central moment - the third root of the skewness\n",
    "        h_skewness = np.mean(abs(h - h.mean())**3)\n",
    "        s_skewness = np.mean(abs(s - s.mean())**3)\n",
    "        v_skewness = np.mean(abs(v - v.mean())**3)\n",
    "        h_thirdMoment = h_skewness**(1./3)\n",
    "        s_thirdMoment = s_skewness**(1./3)\n",
    "        v_thirdMoment = v_skewness**(1./3)\n",
    "        color_feature.append([h_thirdMoment, s_thirdMoment, v_thirdMoment])\n",
    "\n",
    "        return np.array(color_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "ntdUgYO9PK7y"
   },
   "outputs": [],
   "source": [
    "class GaborExtractor(FeatureExtractor):\n",
    "\n",
    "    def __init__(self, dataset_folder):\n",
    "        super().__init__(dataset_folder)\n",
    "        self.kernels = GaborExtractor.gabor_kernel()\n",
    "        if not os.path.isfile(f'{dataset_folder}-Reference.npy'):\n",
    "            self.prepare_reference(dataset_folder)\n",
    "        self.reference = np.load(f'{dataset_folder}-Reference.npy')\n",
    "\n",
    "    @staticmethod\n",
    "    def convolution(image, filters):\n",
    "        result = np.zeros_like(image, dtype=float)\n",
    "        # Normalize images for better comparison.\n",
    "        # image = (image - image.mean()) // image.std()\n",
    "        for kern in filters:\n",
    "            fimg = cv2.filter2D(image, cv2.CV_64FC3, kern)\n",
    "            np.maximum(result, fimg, result)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def gabor_kernel():\n",
    "        filters = []\n",
    "        ksize = 32\n",
    "        # define the range for theta and nu\n",
    "        for theta in np.arange(0, np.pi, np.pi / 8):\n",
    "            for nu in np.arange(np.pi / 4, 6*np.pi/4, np.pi / 4):\n",
    "                kern = cv2.getGaborKernel(\n",
    "                    (ksize, ksize), 1.0, theta, nu, 0.5, 0, ktype=cv2.CV_32F)\n",
    "                kern /= 1.5*kern.sum()\n",
    "                filters.append(kern)\n",
    "        return np.array(filters)\n",
    "\n",
    "    def feature_from_image(self, image):\n",
    "        # initializing the feature vector\n",
    "        feat = []\n",
    "        # calculating the local energy for each convolved image\n",
    "        for j in range(self.kernels.shape[0]):\n",
    "            res = GaborExtractor.convolution(image, self.kernels[j])\n",
    "            feat.append(np.mean(res))\n",
    "            feat.append(np.std(res))\n",
    "        return np.array(feat)\n",
    "\n",
    "    def prepare_reference(self, dataset, folder='Reference'):\n",
    "        train_data_path = os.path.join(dataset, folder)\n",
    "        image_list = sorted([item for item in os.listdir(\n",
    "            train_data_path) if item.endswith('.jpg')])\n",
    "        total = len(image_list)\n",
    "\n",
    "        print('-'*30)\n",
    "        print('Preparing reference...')\n",
    "        print('-'*30)\n",
    "\n",
    "        features = np.ndarray((total, 80), np.float32)\n",
    "\n",
    "        async_results = []\n",
    "        pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())\n",
    "        for idx, image_name in enumerate(image_list):\n",
    "            img = cv2.imread(os.path.join(train_data_path, image_name))\n",
    "            img = cv2.resize(img, (0, 0), fx=0.25, fy=0.25)\n",
    "            async_results.append(pool.apply_async(\n",
    "                self._reference_worker, (img, idx)))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        for async_result in async_results:\n",
    "            feature, idx = async_result.get()\n",
    "            features[idx] = feature\n",
    "        print('Loading done.')\n",
    "\n",
    "        np.save(f'{dataset}-{folder}.npy', features)\n",
    "        print(f'Saving to {dataset}-{folder}.npy files done.')\n",
    "\n",
    "    def extract_from_dataset(self):\n",
    "        subfolders = [item for item in os.listdir(self.dataset_folder) if not item.startswith('.') and item != 'Reference']\n",
    "        top1_sum = 0\n",
    "        top5_sum = 0\n",
    "        total_count = 0\n",
    "        for subfolder in subfolders:\n",
    "            top1_count, top5_count = self._extract_from_subfolder(subfolder)\n",
    "            top1_sum += top1_count\n",
    "            top5_sum += top5_count\n",
    "            total_count += len(self.reference)\n",
    "\n",
    "        return top1_sum, top5_sum, total_count\n",
    "\n",
    "    def _extract_from_subfolder(self, subfolder):\n",
    "        train_data_path = os.path.join(self.dataset_folder, subfolder)\n",
    "        images = sorted([item for item in os.listdir(\n",
    "            train_data_path) if item.endswith('.jpg')])\n",
    "\n",
    "        total = len(images)\n",
    "        top1_count = 0\n",
    "        top5_count = 0\n",
    "\n",
    "        print('-'*30)\n",
    "        print(f'Classifying {subfolder}...')\n",
    "        print('-'*30)\n",
    "        start = time.time()\n",
    "        pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())\n",
    "        async_results = []\n",
    "        for idx, image_name in enumerate(images):\n",
    "            img = cv2.imread(os.path.join(train_data_path, image_name))\n",
    "            img = cv2.resize(img, (0, 0), fx=0.25, fy=0.25)\n",
    "            # top1, top5 = self._worker(idx, img, image_name, total)\n",
    "            # top1_count += top1\n",
    "            # top5_count += top5\n",
    "            async_results.append(pool.apply_async(\n",
    "                self._worker, (idx, img, image_name, total)))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        for async_result in async_results:\n",
    "            top1, top5 = async_result.get()\n",
    "            top1_count += top1\n",
    "            top5_count += top5\n",
    "\n",
    "        end = time.time()\n",
    "        print(f\"time:{end - start}\")\n",
    "        print('All done.')\n",
    "        return top1_count, top5_count\n",
    "\n",
    "    def _reference_worker(self, img, idx):\n",
    "        feature = self.feature_from_image(img)\n",
    "        return feature, idx\n",
    "\n",
    "    def _worker(self, idx, img, image_name, total):\n",
    "        feature = self.feature_from_image(img)\n",
    "        possible_values = []\n",
    "        top1_count = 0\n",
    "        top5_count = 0\n",
    "        for reference_index in range(self.reference.shape[0]):\n",
    "            substracted_mat = np.subtract(\n",
    "                self.reference[reference_index], feature)\n",
    "            distance = norm(substracted_mat)\n",
    "            heapq.heappush(possible_values, (distance, reference_index))\n",
    "        top5_values = []\n",
    "        for i in range(5):\n",
    "            top5_values.append(heapq.heappop(possible_values))\n",
    "        top5 = [index for distance, index in top5_values]\n",
    "\n",
    "        if idx in top5_values[0]:\n",
    "            top1_count += 1\n",
    "            print(f'hit: {image_name}! Distance:{top5_values[0][0]}')\n",
    "\n",
    "        if idx in top5:\n",
    "            top5_count += 1\n",
    "            distance, index = [\n",
    "                entry for entry in top5_values if entry[1] == idx][0]\n",
    "            print(f'hit in top 5: {image_name}! Distance:{distance}')\n",
    "        if idx % 10 == 0:\n",
    "            print(f'Done: {idx}/{total} images')\n",
    "\n",
    "        return top1_count, top5_count\n",
    "\n",
    "\n",
    "class DogSIFTExtactor(FeatureExtractor):\n",
    "    def __init__(self, dataset_folder):\n",
    "        self.dataset_folder = dataset_folder\n",
    "        if not os.path.isfile(f'{dataset_folder}-Reference.npy'):\n",
    "            self.prepare_reference(dataset_folder)\n",
    "        self.reference = np.load(f'{dataset_folder}-Reference.npy')\n",
    "    \n",
    "    def prepare_reference(self, dataset, folder='Reference'):\n",
    "        pass\n",
    "    def extract_from_dataset(self):\n",
    "        train_data_path = os.path.join(self.dataset_folder, 'Reference')\n",
    "        image_list = sorted([item for item in os.listdir(\n",
    "            train_data_path) if item.endswith('.jpg')])\n",
    "        total = len(image_list)\n",
    "        \n",
    "        print('-'*30)\n",
    "        print(f'Classifying Reference...')\n",
    "        print('-'*30)\n",
    "        \n",
    "        for idx, image_name in enumerate(image_list[:1]):\n",
    "            img = cv2.imread(os.path.join(train_data_path, image_name))\n",
    "            gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            sift = cv2.xfeatures2d.SIFT_create()\n",
    "            kp = sift.detect(gray,None)\n",
    "            img = cv2.drawKeypoints(gray,kp)\n",
    "            plt.imshow(img, cmap='gray')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "ntdUgYO9PK7y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Classifying Reference...\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.3) /Users/travis/build/skvark/opencv-python/opencv_contrib/modules/xfeatures2d/src/sift.cpp:1207: error: (-213:The function/feature is not implemented) This algorithm is patented and is excluded in this configuration; Set OPENCV_ENABLE_NONFREE CMake option and rebuild the library in function 'create'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0871d198886e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'dataset/dvd_covers'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfeature_extactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDogSIFTExtactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfeature_extactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_from_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# print(f\"top1:{top1result/total_count}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-42f8063dbb6e>\u001b[0m in \u001b[0;36mextract_from_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mgray\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0msift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxfeatures2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIFT_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0mkp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawKeypoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.3) /Users/travis/build/skvark/opencv-python/opencv_contrib/modules/xfeatures2d/src/sift.cpp:1207: error: (-213:The function/feature is not implemented) This algorithm is patented and is excluded in this configuration; Set OPENCV_ENABLE_NONFREE CMake option and rebuild the library in function 'create'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import cv2\n",
    "\n",
    "dataset_folder = 'dataset/dvd_covers'\n",
    "feature_extactor = DogSIFTExtactor(dataset_folder)\n",
    "feature_extactor.extract_from_dataset()\n",
    "\n",
    "# print(f\"top1:{top1result/total_count}\")\n",
    "# print(f\"top5:{top5result/total_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B8dN_1RRvt3K"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3addf1ac3c1945fc972e3075c23bfae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.5707963267948966, description='theta', max=3.141592653589793, step=0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.demoGabor(theta, omega)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.html.widgets import interact, interactive, fixed\n",
    "def demoGabor(theta, omega):\n",
    "    ksize = 128\n",
    "    kern = cv2.getGaborKernel(\n",
    "                    (ksize, ksize), 5.0, theta, 1/omega, 0.5, 0, ktype=cv2.CV_32F)\n",
    "    kern /= 1.5*kern.sum()\n",
    "    plt.imshow(kern, cmap='gray')\n",
    "\n",
    "interact(demoGabor, theta=(0,np.pi,np.pi/8), omega=(0.1,1,0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Cognative_hw2.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
